\section{pbrt的并行化}\label{sec:pbrt的并行化}

现在几乎不可能买到只有一个处理核的新笔记本或台式计算机了
（甚至对许多手机而言也是如此）。
今天和未来的计算机系统在CPU和
高并行吞吐量处理器如GPU上都会
有越来越多的处理核心。
同时，核心的计算能力却提升缓慢；
因此随着时间推移，
明显的性能提升只会出现在可以\keyindex{并行}{parallel}{}运行的程序上，
其许多独立的执行\keyindex{线程}{thread}{}同时在多核上进行计算。

编写并行程序比写\keyindex{串行}{serial}{}程序复杂得多。
当两组程序员认为该独立同时执行的计算意外相互影响时，
程序可能会崩溃或产生意外结果。
然而，再次运行程序时这种bug可能不会再出现，
因为那些特定计算下次再运行时可能没有同时执行。
幸运的是，有越来越多有用的工具帮助开发者找出这类问题。

并行程序为了良好扩展到多核上，
需要能提供大量独立运算：
任何依赖于先前计算结果的运算都不能
与被依赖者同时执行。
幸运的是，大多数基于光线追踪的渲染算法具有丰富的\keyindex{并行性}{parallelism}{}；
对于\refvar{SamplerIntegrator}{}，
每个图像样本之间都相互独立，
高质量图像可能会用几百万个样本。

并行光线追踪最大的挑战之一是非并行计算阶段的影响。
例如在构建场景时，高效地并行化许多加速结构的构造
并不像并行化渲染那样简单。
但这看起来是个小问题，因为\keyindex{阿姆达尔定律}{Amdahl's law}{}描述了
同时具有串行和并行阶段的工作负载的加速问题这一挑战。
设有$n$个核执行计算，全部工作负载中占比$s$的部分是固有串行的，
则可能的最大加速比是
\begin{align*}
    \frac{1}{\displaystyle s+\frac{1}{n}(1-s)}\, .
\end{align*}
因此，即使有无限多数量的核，加速比最多为$\displaystyle\frac{1}{s}$.
例如如果解析场景文件和建立加速结构的串行阶段
所花的时间占了看似无妨的5\%，
则不论并行阶段执行得有多快，
可能的加速比最多为1/0.05=20倍。

\subsection{数据竞争与协调}
pbrt中，我们假设运算在提供\keyindex{连续共享内存}{coherent shared memory}{}的处理器上运行。
连续共享内存的主要含义是
所有线程都能读写一组公共内存地址，
一个线程对内存的更改最终能被其他其他线程可见。
这种属性极大简化了系统的实现，
因为核之间不需要显式地交换数据。
（连续共享内存在如今的CPU上一般都是可用的
且可能在未来CPU上继续使用。
另一方面，如果在集群的多台计算机上执行计算，
一般是不提供连续共享内存的。）

尽管连续共享内存摆脱了为独立线程互相显式交换数据的需求，
它们仍需要\keyindex{协调}{coordinate}{}对共享数据的访问；
连续共享内存的一大危险是数据\keyindex{竞争}{race}{}。
如果两个线程互相没有协调就修改同一内存地址，
则程序几乎一定会计算出错误结果甚至崩溃。
考虑两个处理器同时运行如下看似无妨的代码例子，
其中{\ttfamily globalCounter}初始值是2：
\begin{lstlisting}
extern int globalCounter;
if (--globalCounter == 0)
    printf("done!\n");
\end{lstlisting}

因为两个线程没有协调它们对{\ttfamily globalCounter}的读写，
有可能会打印零次、一次甚至两次“done”！
编译器生成的汇编指令可能与如下步骤对应：
\begin{lstlisting}
extern int globalCounter;
int temp = globalCounter;
temp = temp - 1;
globalCounter = temp;
if (globalCounter == 0)
    printf("done!\n");
\end{lstlisting}

现在，考虑两个处理器执行这段代码的不同方式。
例如，第二个处理器可能比第一个开始得稍稍晚一些，
但第一个可能执行开始几条指令后就空转\sidenote{译者注：原文go idle。}了几个时钟周期：
\begin{lstlisting}
Thread A                          Thread B
int temp = globalCounter;   
temp = temp - 1;                  // (idle)
globalCounter = temp;             
                                  int temp = globalCounter;
/* (idle) */                         temp = temp - 1;
                                  globalCounter = temp;
if (globalCounter == 0)           if (globalCounter == 0)
    printf("done!\n");                printf("done!\n");
\end{lstlisting}
（从系统中断线程到丢失缓存等,
许多不可预测的事件会造成
这类执行泡沫\sidenote{译者注：原文execution bubbles。}。）
在这个顺序下，两个线程都从{\ttfamily globalCounter}读到零值，
都执行调用{\ttfamily printf()}。
此时，错误不是致命的，
但如果{\ttfamily if}块里换成系统释放资源，
则会企图释放同一资源两次，
这很可能引发崩溃。
现在考虑这种可能的执行顺序：
\begin{lstlisting}
Thread A                          Thread B
int temp = globalCounter;         int temp = globalCounter;
temp = temp - 1;                  temp = temp - 1;
globalCounter = temp;             // (idle)
/* (idle) */                         globalCounter = temp;
if (globalCounter == 0)           if (globalCounter == 0)
    printf("done!\n");                printf("done!\n");
\end{lstlisting}

这种情况下{\ttfamily globalCounter}最终为1，
两个线程都不执行{\ttfamily if}块。
这些例子说明了当执行多线程访问共享可改数据时
它们必须以某种方式\keyindex{同步}{synchronize}{}其访问的原则。

如今有两套主要机制可用于完成这类同步：\keyindex{互斥}{mutual exclusion}{}和\keyindex{原子操作}{atomic operation}{}。
pbrt中用{\ttfamily std::mutex}对象实现互斥。
{\ttfamily std::mutex}能用于阻止访问某些资源，
确保一次只有一个线程可以访问。
考虑之前计算的如下升级版；
这里{\ttfamily std::lock\_guard}对象需要获取互斥锁
并在离开最后大括号作用域时释放它。
\begin{lstlisting}
extern int globalCounter;
extern std::mutex globalCounterMutex;
{   std::lock_guard<std::mutex> lock(globalCounterMutex);
    int temp = globalCounter;
    temp = temp - 1;
    globalCounter = temp;
    if (globalCounter == 0)
        printf("done!\n");
}
\end{lstlisting}
如果两个线程执行这段代码并同时尝试获取互斥锁，
则互斥锁会只允许其中一个继续执行，
而让另一个在{\ttfamily std::lock\_guard}的构造函数中暂停。
只有当第一个线程完成计算
且它的{\ttfamily std::lock\_guard}离开作用域
并释放互斥锁，
第二个线程才能获取到互斥锁并继续计算。
\begin{lstlisting}
Thread A                              Thread B
{ std::lock_guard<std::mutex> lock(   { std::lock_guard<std::mutex> lock(
    globalCounterMutex);                  globalCounterMutex);
  int temp = globalCounter;             // (stalled by mutex)
  // …
} // (mutex released)
                                        // (mutex acquired)
                                        int temp = globalCounter;
                                        // …
                                      } // (mutex released)
\end{lstlisting}

正确互斥后，不论两个线程的执行顺序如何，
{\ttfamily printf()}都只会执行一次。

原子内存操作（或\keyindex{原子}{atomic}{}）是正确执行这类多线程内存更新的另一选择。
原子是保证各自内存更新会在单次处理中执行的机器指令
（这里的\emph{原子}表示内存更新不可分割的概念）。
pbrt中原子操作的实现来自于C++11标准库，
会在附录\refsub{原子操作}讨论。
使用原子，前面的计算可以写成使用类型{\ttfamily std::atomic<int>}，
它重载了加、减、增一、减一操作，如下：
\begin{lstlisting}
extern std::atomic<int> globalCounter;
if (--globalCounter == 0)
    printf("done!\n");
\end{lstlisting}

{\ttfamily std::atomic}的{\ttfamily -}操作符
从给定变量{\ttfamily globalCounter}减去1，
并返回变量的新值。
使用原子操作保证了如果有两个线程同时尝试更新变量时
则不仅最终的变量值是正确的而且
每个线程都会被返回其单独更新后的变量值。
于是在这个例子中，{\ttfamily globalCounter}最终会如愿变为零值，
且一个线程保证从原子减法获得返回值1而另一个保证返回的是0.

还有一个选择是\keyindex{事务内存}{transactional memory}{}，
它在本书编写时才刚在CPU上兴起。
有了事务内存，一组内存写操作会绑为一个事务；
当执行事务时，如果没有其他线程访问这些内存地址，
则所有的写操作都会提交为单个原子操作。
否则，它会回滚使之不写入内存，因此计算没有影响；
事务必须稍后再试。
事务内存利于联系原子的良好细粒度操作和互斥锁的高开销。
然而因为它还没有广泛运用，pbrt目前不使用事务内存。

附录中\refsec{并行化}有关于并行编程的更多信息、
性能问题和陷阱的额外细节以及pbrt并行实现所用的各种例程。

\subsection{pbrt中的约定}\label{sub:pbrt中的约定}
pbrt中（大多数光线追踪器也适用）
渲染时绝大部分数据都是只读的
（例如场景描述和纹理贴图\sidenote{译者注：原文texture map，也称纹理映射。}）。
几乎所有场景文件的解析和内存中场景描述的创建都由单个执行线程完成，
所以该执行阶段无同步问题
\footnote{两个例外是在图像纹理贴图上做一些图像重采样，
    以及\protect\refvar{BVHAccel}{}变体的构造，
    不过它们都是高度局部化的。}。
渲染时，多线程对所有只读数据的并发访问不会出问题；
我们只需关心内存中要修改数据的情况。

向pbrt新增代码时，要注意保证不要在没有适当同步时
不经意添加修改共享数据的代码。
这通常很简单；
例如，当新增一个\refvar{Shape}{}的实现时，
\refvar{Shape}{}通常只在其成员变量创建后才执行读取操作。
然而有时会不经意引入共享数据。
考虑如下常见于单线程代码的习惯写法：
\begin{lstlisting}
static bool firstCall = true;
if (firstCall) {
    // additional initialization …
    firstCall = false;
}
\end{lstlisting}

多线程执行这段代码是不安全的，
因为多线程见到的{\ttfamily firstCall}值
可能是{\ttfamily true}然后全都执行初始化代码。
安全的写法需要原子操作或互斥锁
（这样的习惯用法也可以用函数{\ttfamily std::call\_once()}安全实现）。

\subsection{pbrt中的线程安全要求}

pbrt中许多类方法都要求是并发多线程执行安全的。
这些方法的特定实例为了安全执行，所需的任何更新必须是安全的，
即要么不用更新共享全局数据，要么必须使用互斥锁或原子操作。

一般而言，系统底层类或结构体是线程不安全的。
例如，类\refvar{Point3f}{}存储了
三个{\ttfamily float}值来表示3D空间的点，
对于多线程而言调用方法同时修改它是不安全的
（当然多线程可以同时用\refvar{Point3f}{}作为只读数据）。
让\refvar{Point3f}{}变得线程安全的运行时开销会对
性能有极大影响但回报甚少。

像\refvar{Vector3f}{}、\refvar{Normal3f}{}、
\refvar{Spectrum}{}、\refvar{Transform}{}、
\refvar{SurfaceInteraction}{}
和
\refvar{Quaternion}{}
这些类也是这样。
这些类通常在场景构造时创建再用作只读数据
或者在渲染时分配到堆栈上只供单线程使用。

实用类\refvar{MemoryArena}{}（用于高性能临时内存分配）
和\refvar{RNG}{}（伪随机数生成）用于多线程也不安全；
这些类的方法被调用时会修改其保存的状态，
而用互斥锁阻止修改它们状态的开销比它们执行的计算量还多。
因此，像上面方法\refvar{SamplerIntegrator::Render}{()}那样，
实现会在堆栈上分配这些类的每个线程实例。

除了两个例外，列于\reftab{1.1}的高级抽象类的实现
全都应该对多线程同时使用是安全的。
通常稍加注意就能很简单地实现这些基类的特定实例
而不会在其方法里修改任何共享数据。

第一个例外是\refvar{SamplerIntegrator}{}和\refvar{Light}{}的
方法{\ttfamily Preprocess()}。
它们在场景构建时被系统调用，
它们的实现通常会修改其实现里的共享状态——
例如构建表示场景中光照分布的数据结构体。
因此，允许实现者假设只有单个线程会调用这些方法是有益的
（这和考虑到这些计算密集型方法的实现
可能使用\refvar{ParallelFor}{()}来并行化其计算是独立的问题）。

第二个例外是\refvar{Sampler}{}；
其方法也不用是线程安全的。
这是该要求会引发过多执行量和可扩展性影响的又一例子；
许多线程同时试图从单个\refvar{Sampler}{}获取样本
会限制系统的整体性能。
因此如\refsub{主渲染循环}所述，
用\refvar[Clone]{Sampler::Clone}{()}为
每个图块创建唯一\refvar{Sampler}{}；
该采样器之后只能用于该图块，无任何互斥开销。

pbrt中所有的独立\sidenote{译者注：原文stand-alone。}函数
都是线程安全的（只要多线程不给它们传入指向相同数据的指针）。